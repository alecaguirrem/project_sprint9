{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"header\" align=\"center\">\n",
    "\n",
    "# Introducción\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este proyecto se va a analizar una base de datos de usuarios de la compañía **Megaline**, los cuales están divididos en dos tipos de planes *Smart* y *Ultra*. \n",
    "\n",
    "El objetivo de éste analisis es el de crear un modelo de ML que pueda clasificar a los clientes basado en sus consumos de llamadas, mensajes y megabytes para así decidir si cada usuario debería pertener al plan *Smart* o si cambiar al plan *Ultra* sería una mejor opción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importación de librerias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que se van a utilizar distintos modelos voy a importar las librerias y métodos vistos en el Sprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Modelos de ML\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Segmentación de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Métricas de evaluación.\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/datasets/Sprint 9/users_behavior.csv')\n",
    "\n",
    "display(df.head())\n",
    "print()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Segmentación de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a segmentar los datos en 3 con los siguientes porcentajes:\n",
    "\n",
    "|    Conjunto   | Porcentaje |\n",
    "|---------------|------------|\n",
    "| Entrenamiento |    60 %    |\n",
    "|   Validación  |    20 %    |\n",
    "|    Pruebas    |    20 %    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "# Primero separo en un 80% (entrenamiento + validación) y 20% (pruebas)  \n",
    "x_train, features_test, y_train, target_test = train_test_split(features, target, test_size=0.2, random_state=123)\n",
    "\n",
    "# Después el 80% se divide en el 25% y 75%. De este modo ((0.25 * 0.8) + (0.75 * 0.8)) + (0.2) = 1\n",
    "features_train, features_val, target_train, target_val = train_test_split(x_train, y_train, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilicé la divisón train_test_split() dos veces, debido a que se van a separar los datos de la siguiente manera para evitar el sobreajuste con el modelo entrenado...\n",
    "\n",
    "| Tipos de datos |% del total | sub % |\n",
    "|----------------|------------|-------|\n",
    "|  Entrenamiento |    60 %    |  75%  |\n",
    "|    Validación  |    20 %    |  25%  |\n",
    "|     Prueba     |    20 %    |       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Prueba de diferentes modelos de ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al buscar un modelo de decisión donde el resultado para las predicciones solo existen dos posibles respuestas (0 o 1). Los métodos más apropiados son los de Arboles de Decisión, Bosque Aleatorio, Regresióm Lógistca, SVM, KNN, Gradient Boosting y Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Arboles de Decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero voy a entrenar el dataset de *features_train* con el algoritmo de aprendizaje *DecisionTreeClassifier* para obtener un modelo entrenado y después utilizar el *features_val* para validar las predicciones y ya después vealuar con diferentes métricas la calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento.\n",
    "model_tree = DecisionTreeClassifier(random_state=123)\n",
    "model_tree.fit(features_train,target_train)\n",
    "\n",
    "# Aplicación.\n",
    "pred_val = model_tree.predict(features_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.1.1 Métricas de evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a determinar la exactitud del modelo entrenado que generamos, comparando la variable *pred_val* contra *target_val*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del árbol de decisiones en base al dataset de validación es de: 72.47278382581649\n"
     ]
    }
   ],
   "source": [
    "print(f'La exactitud del árbol de decisiones en base al dataset de validación es de: {(accuracy_score(target_val,pred_val))*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a hacer algunos ejercicios para determinar que hiperparámetros podemos modificar en el modelo para mejorar sus métricas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con una profundidad de 1 la mejor exactitud del modelo es de 73.56143079315707\n",
      "Con una profundidad de 2 la mejor exactitud del modelo es de 76.51632970451011\n",
      "Con una profundidad de 3 la mejor exactitud del modelo es de 78.38258164852256\n",
      "Con una profundidad de 6 la mejor exactitud del modelo es de 78.84914463452566\n",
      "Con una profundidad de 9 la mejor exactitud del modelo es de 79.47122861586314\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for depth in range(1,31):\n",
    "    model_tree_alt = DecisionTreeClassifier(random_state=123,max_depth=depth)\n",
    "    model_tree_alt.fit(features_train,target_train)\n",
    "    pred_val_alt = model_tree_alt.predict(features_val)\n",
    "    actual_score = accuracy_score(target_val,pred_val_alt)*100\n",
    "    if actual_score > best_score:\n",
    "        print(f'Con una profundidad de {depth} la mejor exactitud del modelo es de {actual_score}')\n",
    "        best_score = actual_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La exactitud del modelo es mucho mejor definiendo la profundidad del árbol en 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.0715396578538\n"
     ]
    }
   ],
   "source": [
    "model_tree_alt = DecisionTreeClassifier(random_state=123,max_depth=9,criterion='entropy')\n",
    "model_tree_alt.fit(features_train,target_train)\n",
    "pred_val_alt = model_tree_alt.predict(features_val)\n",
    "actual_score = accuracy_score(target_val,pred_val_alt)*100\n",
    "print(actual_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es mejor dejar el hiperparámetro criterion en 'gini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.60497667185071\n"
     ]
    }
   ],
   "source": [
    "model_tree_alt = DecisionTreeClassifier(random_state=123,max_depth=9,splitter='random')\n",
    "model_tree_alt.fit(features_train,target_train)\n",
    "pred_val_alt = model_tree_alt.predict(features_val)\n",
    "actual_score = accuracy_score(target_val,pred_val_alt)*100\n",
    "print(actual_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es mejor dejar el hiperparámetro splitter en 'best'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 2 muestras, la exactitud del modelo es de 79.47122861586314\n",
      "Con 11 muestras, la exactitud del modelo es de 79.62674961119751\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for samples in range(2,21):\n",
    "    model_tree_alt = DecisionTreeClassifier(random_state=123,max_depth=9,min_samples_split=samples)\n",
    "    model_tree_alt.fit(features_train,target_train)\n",
    "    pred_val_alt = model_tree_alt.predict(features_val)\n",
    "    actual_score = accuracy_score(target_val,pred_val_alt)*100\n",
    "    if actual_score > best_score:\n",
    "        print(f'Con {samples} muestras, la exactitud del modelo es de {actual_score}')\n",
    "        best_score = actual_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien, tener una mejora de 0.15% no parece un aumento significativo voy a usar el min_samples_split = 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 1 muestras, la exactitud del modelo es de 79.62674961119751\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for samples in range(1,11):\n",
    "    model_tree_alt = DecisionTreeClassifier(random_state=123,max_depth=9,min_samples_split=11,min_samples_leaf=samples)\n",
    "    model_tree_alt.fit(features_train,target_train)\n",
    "    pred_val_alt = model_tree_alt.predict(features_val)\n",
    "    actual_score = accuracy_score(target_val,pred_val_alt)*100\n",
    "    if actual_score > best_score:\n",
    "        print(f'Con {samples} muestras, la exactitud del modelo es de {actual_score}')\n",
    "        best_score = actual_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con 11 muestras, la exactitud del modelo es de 78.69362363919129\n",
      "Con 21 muestras, la exactitud del modelo es de 78.84914463452566\n",
      "Con 31 muestras, la exactitud del modelo es de 79.16018662519441\n",
      "Con 41 muestras, la exactitud del modelo es de 79.62674961119751\n",
      "Con 51 muestras, la exactitud del modelo es de 79.93779160186625\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "for leaf in range(11,211,10):\n",
    "    model_tree_alt = DecisionTreeClassifier(random_state=123,max_depth=9,min_samples_split=11,max_leaf_nodes=leaf)\n",
    "    model_tree_alt.fit(features_train,target_train)\n",
    "    pred_val_alt = model_tree_alt.predict(features_val)\n",
    "    actual_score = accuracy_score(target_val,pred_val_alt)*100\n",
    "    if actual_score > best_score:\n",
    "        print(f'Con {leaf} muestras, la exactitud del modelo es de {actual_score}')\n",
    "        best_score = actual_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ajustar el hiperparámetro max_leaf_nodes = 51 ya que fue el valor que elevó la exactitud del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con el valor None en el hiperparámetro max_features, la exactitud del modelo es de 79.93779160186625\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "list = [None,'sqrt','log2',2,0.75]\n",
    "for each in list:\n",
    "    model_tree_alt = DecisionTreeClassifier(random_state=123,max_depth=9,min_samples_split=11,max_leaf_nodes=51,max_features=each)\n",
    "    model_tree_alt.fit(features_train,target_train)\n",
    "    pred_val_alt = model_tree_alt.predict(features_val)\n",
    "    actual_score = accuracy_score(target_val,pred_val_alt)*100\n",
    "    if actual_score > best_score:\n",
    "        print(f'Con el valor {each} en el hiperparámetro max_features, la exactitud del modelo es de {actual_score}')\n",
    "        best_score = actual_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con el valor None en el hiperparámetro class_weight, la exactitud del modelo es de 79.93779160186625\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "list = [None,'balanced']\n",
    "for each in list:\n",
    "    model_tree_alt = DecisionTreeClassifier(random_state=123,max_depth=9,min_samples_split=11,max_leaf_nodes=51,class_weight=each)\n",
    "    model_tree_alt.fit(features_train,target_train)\n",
    "    pred_val_alt = model_tree_alt.predict(features_val)\n",
    "    actual_score = accuracy_score(target_val,pred_val_alt)*100\n",
    "    if actual_score > best_score:\n",
    "        print(f'Con el valor {each} en el hiperparámetro class_weight, la exactitud del modelo es de {actual_score}')\n",
    "        best_score = actual_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Evaluación del Modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo con el dataset de prueba es de: 78.84914463452566\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "model_tree_test = DecisionTreeClassifier(random_state=123,max_depth=9,min_samples_split=11,max_leaf_nodes=51)\n",
    "model_tree_test.fit(features_train,target_train)\n",
    "\n",
    "# Aplicación\n",
    "pred_test = model_tree_test.predict(features_test)\n",
    "print(f'La exactitud del modelo con el dataset de prueba es de: {accuracy_score(target_test,pred_test)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Árboles Aleatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero voy a entrenar el dataset de *features_train* con el algoritmo de aprendizaje *RandomForestClassifier* para obtener un modelo entrenado y después utilizar el *features_val* para validar las predicciones y ya después vealuar con diferentes métricas la calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento.\n",
    "model_rt_tree = RandomForestClassifier(random_state=123)\n",
    "model_rt_tree.fit(features_train,target_train)\n",
    "\n",
    "# Aplicación.\n",
    "pred_rt_val = model_rt_tree.predict(features_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 Métricas de evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a determinar la exactitud del modelo entrenado que generamos, comparando la variable *pred_val* contra *target_val*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo árboles aleatorios en base al dataset de validación es de: 80.09331259720062\n"
     ]
    }
   ],
   "source": [
    "print(f'La exactitud del modelo árboles aleatorios en base al dataset de validación es de: {(accuracy_score(target_val,pred_rt_val))*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer menos ejercicios individuales modificando hiperparámetros de manera individual para encontrar la mejor combinacioon, voy a utilizar GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Mejores hiperparámetros: {'max_depth': 8, 'n_estimators': 130}\n"
     ]
    }
   ],
   "source": [
    "# Voy a utilizar solo 2 ya que en un inicio use como 7 hiperparámetros y me resultaba en 38,000,000 de combinaciones\n",
    "param_grid = {\n",
    "    'n_estimators': [100,110,120,130,140,150],\n",
    "    'max_depth' : [1,2,3,4,5,6,7,8,9,10],\n",
    "}\n",
    "\n",
    "rt = RandomForestClassifier(random_state=123)\n",
    "grid_search = GridSearchCV(rt, param_grid=param_grid, cv=5, scoring='accuracy',verbose=1)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2 Evaluación del Modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo con el dataset de prueba es de: 81.18195956454122\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "model_rt_tree_test = RandomForestClassifier(random_state=123,n_estimators=130,max_depth=8)\n",
    "model_rt_tree_test.fit(features_train,target_train)\n",
    "\n",
    "# Aplicación\n",
    "pred_test_rt = model_rt_tree_test.predict(features_test)\n",
    "print(f'La exactitud del modelo con el dataset de prueba es de: {accuracy_score(target_test,pred_test_rt)*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Gradient Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero voy a entrenar el dataset de *features_train* con el algoritmo de aprendizaje *GradientBoostingClassifier* para obtener un modelo entrenado y después utilizar el *features_val* para validar las predicciones y ya después vealuar con diferentes métricas la calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento.\n",
    "model_boost = GradientBoostingClassifier(random_state=123)\n",
    "model_boost.fit(features_train,target_train)\n",
    "\n",
    "# Aplicación.\n",
    "pred_boost_val = model_boost.predict(features_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.1 Métricas de evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a determinar la exactitud del modelo entrenado que generamos, comparando la variable *pred_val* contra *target_val*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo gradient boosting en base al dataset de validación es de: 78.84914463452566\n"
     ]
    }
   ],
   "source": [
    "print(f'La exactitud del modelo gradient boosting en base al dataset de validación es de: {(accuracy_score(target_val,pred_boost_val))*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer menos ejercicios individuales modificando hiperparámetros de manera individual para encontrar la mejor combinacioon, voy a utilizar GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Mejores hiperparámetros: {'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100,110,120,130,140,150],\n",
    "}\n",
    "\n",
    "boost = GradientBoostingClassifier(random_state=123)\n",
    "grid_search = GridSearchCV(boost, param_grid=param_grid, cv=5, scoring='accuracy',verbose=1)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.2 Evaluación del Modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo gradient boosting en base al dataset de prueba es de: 80.87091757387248\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento.\n",
    "model_boost_test = GradientBoostingClassifier(random_state=123,n_estimators=150)\n",
    "model_boost_test.fit(features_train,target_train)\n",
    "\n",
    "# Aplicación.\n",
    "pred_test_boost = model_boost_test.predict(features_test)\n",
    "print(f'La exactitud del modelo gradient boosting en base al dataset de prueba es de: {(accuracy_score(target_test,pred_test_boost))*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 Regresión Logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero voy a entrenar el dataset de *features_train* con el algoritmo de aprendizaje *LogisticRegression* para obtener un modelo entrenado y después utilizar el *features_val* para validar las predicciones y ya después vealuar con diferentes métricas la calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento.\n",
    "model_logic = LogisticRegression(random_state=123)\n",
    "model_logic.fit(features_train,target_train)\n",
    "\n",
    "# Aplicación.\n",
    "pred_logic_val = model_logic.predict(features_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.1 Métricas de evaluación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a determinar la exactitud del modelo entrenado que generamos, comparando la variable *pred_val* contra *target_val*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo regresión logistica en base al dataset de validación es de: 73.40590979782272\n"
     ]
    }
   ],
   "source": [
    "print(f'La exactitud del modelo regresión logistica en base al dataset de validación es de: {(accuracy_score(target_val,pred_logic_val))*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer menos ejercicios individuales modificando hiperparámetros de manera individual para encontrar la mejor combinacioon, voy a utilizar GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Mejores hiperparámetros: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l1','l2'],\n",
    "    'solver' : ['liblinear'],\n",
    "    'C' : [0.1,1,10,100],\n",
    "}\n",
    "\n",
    "linear = LogisticRegression(random_state=123)\n",
    "grid_search = GridSearchCV(linear, param_grid=param_grid, cv=5, scoring='accuracy',verbose=1)\n",
    "grid_search.fit(features_train, target_train)\n",
    "print(\"Mejores hiperparámetros:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.4.2 Evaluación del Modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo Regresión Logística en base al dataset de prueba es de: 74.96111975116641\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento.\n",
    "model_logic_test = LogisticRegression(random_state=123,solver='liblinear',penalty='l1',C=10)\n",
    "model_logic_test.fit(features_train,target_train)\n",
    "\n",
    "# Aplicación.\n",
    "pred_test_logic = model_logic_test.predict(features_test)\n",
    "print(f'La exactitud del modelo Regresión Logística en base al dataset de prueba es de: {(accuracy_score(target_test,pred_test_logic))*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Resumen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente tabla muestra un resumen de los porcentajes obtenidos por diferentes modelos de ML. \n",
    "\n",
    "|      Modelo       |  Exactitud |\n",
    "|-------------------|------------|\n",
    "|Árbol de decisión  |    78.84   |\n",
    "|Árboles aleatorios |    81.18   |\n",
    "|     Gradiente     |    80.87   |\n",
    "|Regresión Logistica|    74.96   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los datos obtenidos con los datasets de prueba para cada modelo de ML, podemos ver que el mejor modelo para evaluar los datos es el de Árboles Aleatorios, seguido del Gradient Boosting, Árbol de Decisión y por último Regresión Logística.\n",
    "\n",
    "Si bien los Árboles Aleatorios y el Gradient Boosting son los mejores con una exactitud de mayor del 80%, llegan a consumir mucha memoria. Si recordamos se nos pide una exactitud mayor al 75% la cual practicamente cumplen también el árbol de decisión y Regresión Loigistica.\n",
    "\n",
    "Con estos resultados se le puede presentar la información a la compañía Megaline y que ellos decidan si están dispuestos a usar los modelos con mayor exactitud y más uso de memoria o estám dispuestos a ceder ese 2-5% de exactitud por un modelo más rápido.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
